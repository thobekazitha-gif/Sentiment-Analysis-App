Limitations of the chosen API and analysis method
The system relies primarily on a third-party Transformer model (via Hugging Face Inference API) with a local VADER fallback. This hybrid approach is practical but introduces several limitations. Models fine-tuned on social media (tweets) or public datasets may carry domain-specific biases: slang, abbreviations, and sarcastic phrasing common in tweets don’t map cleanly to customer reviews, product feedback, or formal survey responses. Consequently, domain shift can reduce accuracy unless the model is fine-tuned on domain-relevant labeled examples.

Confidence scores returned by the API are helpful but not absolute: a softmax score measures the model’s internal certainty among its classes, but a well-calibrated probability requires additional calibration (temperature scaling or Platt scaling). Low confidence often correlates with ambiguous or mixed-sentiment inputs, but occasional high-confidence misclassifications are possible for adversarial or out-of-distribution text. VADER is useful as a deterministic fallback but is rule-based and cannot capture complex syntax or contextual sentiment as well as a modern transformer.

Explainability via LIME provides local, human-readable token importance but is an approximation. LIME perturbs inputs and measures output changes; it can highlight correlated tokens but cannot prove causation and sometimes produces unstable explanations for longer texts. Keyword extraction (RAKE) surfaces salient phrases but does not indicate polarity without cross-referencing with model outputs; low-frequency but sentiment-driving tokens may be omitted.

Operational concerns include API rate limits, latency, cost, and data privacy: sending sensitive user content to a hosted inference API carries compliance risks and may require anonymization or an on-premise model. Finally, handling sarcasm, double-negatives, and domain-specific idioms remains an open challenge without targeted fine-tuning and human-in-the-loop validation. For production, invest in domain-specific labelled data (500–2,000+ examples), model calibration, and continuous monitoring with active learning for the lowest-confidence predictions.
